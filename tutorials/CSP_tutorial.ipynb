{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will create a CSP pipeline using MindPype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to setup the path so we can import the mindpype library\n",
    "import os; os.sys.path.append(os.path.dirname(os.path.abspath('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindpype as mp\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a pipeline is to create a session, which serves as a sandbox for all components in the pipeline. After creating the session we will create a graph which represents the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a session and a graph\n",
    "session = mp.Session.create()\n",
    "trial_graph = mp.Graph.create(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSP requires initialization data to use for training. Therefore, we will randomly generate values for the training data and labels and create tensors from these generated values using the ```create_from_data()``` factory method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random initialization (training) data and labels\n",
    "training_data = np.random.random((120,12,500))\n",
    "labels = np.asarray([0]*60 + [1]*60)\n",
    "\n",
    "\n",
    "# Create tensors from the data and labels\n",
    "init_data = mp.Tensor.create_from_data(session,training_data)\n",
    "init_labels = mp.Tensor.create_from_data(session,labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create our input and output data containers for the graph. Our pipeline will take input data and will output the predicted label so we will create a tensor object for our input and a scalar object for our output.\n",
    "\n",
    "Then we will create virtual tensors to hold ant intermediate values that are calculated throughout the pipeline using the ```create_virtual()``` method. Since these intermediate values represent data that is only required in the proces of completing a calculation and we do not need to access them later, the virtual type is ideal. The virtual type provides temporary storage and enabled us to free up more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input tensor with dummy data\n",
    "input_tensor = mp.Tensor.create_from_data(session, np.random.randn(12, 500))\n",
    "\n",
    "# Create a scalar that will be populated with the classifier label\n",
    "classifier_label = mp.Scalar.create_from_value(session,-1)\n",
    "\n",
    "# Create intermediate (virtual) tensors for the intermediate steps of the pipeline\n",
    "intermediate_tensors = [mp.Tensor.create_virtual(session),\n",
    "                        mp.Tensor.create_virtual(session),\n",
    "                        mp.Tensor.create_virtual(session),\n",
    "                        mp.Tensor.create_virtual(session)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a filter. We first set the parameter values for the filter, then we will use these values to create a butterworth filter using the ```create_butter()``` factory method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filter parameters\n",
    "order = 4\n",
    "bandpass = (8,35) # in Hz\n",
    "fs = 250\n",
    "\n",
    "# Create a filter object using the parameters\n",
    "filter_obj = mp.Filter.create_butter(session,order,bandpass,btype='bandpass',fs=fs,implementation='sos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an LDA classifier to predict the output labels, so we will create a classifier object using the ```create_LDA()``` factory method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier object\n",
    "classifier = mp.Classifier.create_LDA(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add the associated kernels to our graph using the ```add_to_graph()``` factory methods. Each kernel that we add to the graph represents a node that will execute a process. \n",
    "\n",
    "For our CSP pipeline, we will first filter the data. Then we will pass the filtered data (which is stored in a virtual tensor, intermediate_tensor[1]) to our CSP kernel which will calculate and apply our spatial filters to our data. Next, we will apply the variance and log kernels to the spatially filtered data (which is stored in a virtual tensor, intermediate_tensor[2]) to aid with feature extraction. Finally, we will use an LDA classifier to make our output label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the processing nodes to the graph using the factory methods\n",
    "filter_kernel = mp.kernels.FilterKernel.add_to_graph(trial_graph,input_tensor,filter_obj,intermediate_tensors[0], axis = 1)\n",
    "\n",
    "CSP_kernel = mp.kernels.CommonSpatialPatternKernel.add_to_graph(trial_graph, intermediate_tensors[0], intermediate_tensors[1], init_data, init_labels, 2)\n",
    "var_kernel = mp.kernels.VarKernel.add_to_graph(trial_graph, intermediate_tensors[1], intermediate_tensors[2], axis = 1)\n",
    "log_kernel = mp.kernels.LogKernel.add_to_graph(trial_graph, intermediate_tensors[2], intermediate_tensors[3])\n",
    "LDA_kernel = mp.kernels.ClassifierKernel.add_to_graph(trial_graph, intermediate_tensors[3], classifier, classifier_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of our nodes added to our graph, we will then verify the graph using the ```verify()``` method. Verifying the graph orders the nodes for execution and ensure that the inputs and outputs of each processing node are appropriately typed and sized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying kernel Filter...\n",
      "Verifying kernel CSP...\n",
      "Verifying kernel Var...\n",
      "Verifying kernel Log...\n",
      "Verifying kernel Classifier...\n"
     ]
    }
   ],
   "source": [
    "# verify the session (i.e. schedule the nodes) and ensure the inputs and outputs are connected properly\n",
    "trial_graph.verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our graph has been verified, the next step is to initialize the graph. This step is required for pipelines that have methods that need to be trained or fit. For our pipeline the CSP and the LDA nodes require training/initialization so we will call the ```initialize()``` method on our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the graph contains nodes that must be initialzed/trained, we must call initialize() before running the graph\n",
    "trial_graph.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run our pipeline. To run the graph for the provided input data, we use the ```execute()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing trial with label: None\n",
      "Trial 1, Predicted label = 1\n",
      "\n",
      "Test Passed =D\n"
     ]
    }
   ],
   "source": [
    "# RUN!\n",
    "trial_graph.execute()\n",
    "# print the value of the most recent trial\n",
    "print(\"Trial {}, Predicted label = {}\\n\".format(1, classifier_label.data))\n",
    "\n",
    "\n",
    "print(\"Test Passed =D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
