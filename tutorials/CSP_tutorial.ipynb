{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will create a CSP pipeline using MindPype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to setup the path so we can import the mindpype library\n",
    "import os; os.sys.path.append(os.path.dirname(os.path.abspath('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindpype as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a pipeline is to create a session, which serves as a sandbox for all components in the pipeline. After creating the session we will create a graph which represents the pipeline including the processing nodes and the data edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a session and a graph\n",
    "session = mp.Session.create()\n",
    "trial_graph = mp.Graph.create(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSP requires initialization data to use for training. Therefore, we will randomly generate values for the training data and labels and create tensors from these generated values using the ```create_from_data()``` factory method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random initialization (training) data and labels\n",
    "training_data = np.random.random((120,12,500))\n",
    "labels = np.asarray([0]*60 + [1]*60)\n",
    "\n",
    "\n",
    "# Create tensors from the data and labels\n",
    "init_data = mp.Tensor.create_from_data(session,training_data)\n",
    "init_labels = mp.Tensor.create_from_data(session,labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create our input and output data containers for the graph. Our pipeline will take input data and will output the predicted label so we will create a tensor object for our input and a scalar object for our output.\n",
    "\n",
    "Then we will create virtual tensors to hold ant intermediate values that are calculated throughout the pipeline using the ```create_virtual()``` method. Since these intermediate values represent data that is only required in the proces of completing a calculation and we do not need to access them later, the virtual type is ideal. The virtual type provides temporary storage and enabled us to free up more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input tensor with dummy data\n",
    "input_tensor = mp.Tensor.create_from_data(session, np.random.randn(12, 500))\n",
    "\n",
    "# Create a scalar that will be populated with the classifier label\n",
    "classifier_label = mp.Scalar.create_from_value(session,-1)\n",
    "\n",
    "# Create intermediate (virtual) tensors for the intermediate steps of the pipeline\n",
    "intermediate_tensors = [mp.Tensor.create_virtual(session),\n",
    "                        mp.Tensor.create_virtual(session),\n",
    "                        mp.Tensor.create_virtual(session),\n",
    "                        mp.Tensor.create_virtual(session)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a filter. We first set the parameter values for the filter, then we will use these values to create a butterworth filter using the ```create_butter()``` factory method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create filter parameters\n",
    "order = 4\n",
    "bandpass = (8,35) # in Hz\n",
    "fs = 250\n",
    "\n",
    "# Create a filter object using the parameters\n",
    "filter_obj = mp.Filter.create_butter(session,order,bandpass,btype='bandpass',fs=fs,implementation='sos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an LDA classifier to predict the output labels, so we will create a classifier object using the ```create_LDA()``` factory method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier object\n",
    "classifier = mp.Classifier.create_LDA(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add the associated kernels to our graph using the ```add_to_graph()``` factory methods. Each kernel that we add to the graph represents a node that will execute a process. \n",
    "\n",
    "For our CSP pipeline, we will first filter the data. Then we will pass the filtered data (which is stored in a virtual tensor, intermediate_tensor[1]) to our CSP kernel which will calculate and apply our spatial filters to our data. Next, we will apply the variance and log kernels to the spatially filtered data (which is stored in a virtual tensor, intermediate_tensor[2]) to aid with feature extraction. Finally, we will use an LDA classifier to make our output label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the processing nodes to the graph using the factory methods\n",
    "filter_node = mp.kernels.FilterKernel.add_to_graph(trial_graph,input_tensor,filter_obj,intermediate_tensors[0], axis = 1)\n",
    "\n",
    "CSP_node = mp.kernels.CommonSpatialPatternKernel.add_to_graph(trial_graph, intermediate_tensors[0], intermediate_tensors[1], init_data, init_labels, 2)\n",
    "var_node = mp.kernels.VarKernel.add_to_graph(trial_graph, intermediate_tensors[1], intermediate_tensors[2], axis = 1)\n",
    "log_node = mp.kernels.LogKernel.add_to_graph(trial_graph, intermediate_tensors[2], intermediate_tensors[3])\n",
    "LDA_node = mp.kernels.ClassifierKernel.add_to_graph(trial_graph, intermediate_tensors[3], classifier, classifier_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of our nodes added to our graph, we will then verify the graph using the ```verify()``` method. Verifying the graph orders the nodes for execution and ensure that the inputs and outputs of each processing node are appropriately typed and sized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the session (i.e. schedule the nodes) and ensure the inputs and outputs are connected properly\n",
    "trial_graph.verify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our graph has been verified, the next step is to initialize the graph. This step is required for pipelines that have methods that need to be trained or fit. For our pipeline the CSP and the LDA nodes require training/initialization so we will call the ```initialize()``` method on our graph. Note that when we created the graph nodes, we only specified intialization data for the CSP node and did not explicitly provide training data for the classifier node. In these cases, MindPype will identify nodes that require training data but were not exlpicitly provided a reference to training data at node creation. During graph verification, MindPype will automatically search through the upstream nodes (i.e., nodes executed earlier) and identify sources of initialization data. If an upstream node with an initialization data input is found, MindPype will propagate that data through the graph to produce the required training data for the downstream node.\n",
    "\n",
    "For example, in this pipeline, MindPype will flag that the LDA node requires initialization data but has not been explicitly provided any. It will then search through the nodes immediately preceeding it to find any nodes that were provided initialization data (i.e., check the log node, then var node, then CSP). It will find that the CSP node has initialization data and stop searching. When `graph.initialize()` is called, the CSP node will be initialized, and then the initialization data will be propagated through the graph (i.e., the CSP, log, and variance transformations will be applied) until it reaches the LDA node. This transformed initialization data will be used to initialize the LDA classifier. \n",
    "\n",
    "Note that any node can be provided initialization data even if the node itself does not require initialization. In this graph, for example, we could have provided the initialization data to the filter node instead and the initialization data would have been propagated through the graph to initialize both the CSP and LDA nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the graph contains nodes that must be initialzed/trained, we must call initialize() before running the graph\n",
    "trial_graph.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run our pipeline. To run the graph for the provided input data, we use the ```execute()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN!\n",
    "trial_graph.execute()\n",
    "# print the value of the most recent trial\n",
    "print(\"Trial {}, Predicted label = {}\\n\".format(1, classifier_label.data))\n",
    "\n",
    "\n",
    "print(\"Test Passed =D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
