{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows you how to create a pipeline that uses an input LSL stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to setup the path so we can import the mindpype library\n",
    "import os; os.sys.path.append(os.path.dirname(os.path.abspath('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindpype as mp\n",
    "import numpy as np\n",
    "import pylsl\n",
    "\n",
    "# This test requires a running LSL stream with the following properties:\n",
    "# - Type: \"EEG\"\n",
    "\n",
    "# This test also requires a marker stream with the following properties:\n",
    "# - Type: \"Markers\"\n",
    "# - Marker Format: \"^SPACE pressed$\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will specify the channel map and selected channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_map =  {'FCz': 0, 'Fz': 1, 'F3': 2, 'F7': 3, 'FC3': 4, 'T7': 5, 'C5': 6, 'C3': 7, 'C1': 8,\n",
    "        'Cz' : 9, 'CP3': 10, 'CPz': 11, 'P7': 12, 'P5': 13, 'P3': 14, 'P1': 15, 'Pz': 16,\n",
    "        'PO3': 17, 'Oz': 18, 'PO4': 19, 'P8': 20, 'P6': 21, 'P4': 22, 'P2': 23, 'CP4': 24,\n",
    "        'T8' : 25, 'C6': 26, 'C4' : 27, 'C2': 28, 'FC4': 29, 'F4': 30, 'F8': 31}\n",
    "\n",
    "sel_chs = ('FCz',\n",
    "            'Fz',\n",
    "            'F3',\n",
    "            'F7',\n",
    "            'FC3',\n",
    "            'T7',\n",
    "            'C5',\n",
    "            'C3',\n",
    "            'C1',\n",
    "            'Cz',\n",
    "            'CP3',\n",
    "            'CPz',\n",
    "            'P7',\n",
    "            'P5',\n",
    "            'P3',\n",
    "            'P1',\n",
    "            'Pz',\n",
    "            'PO3',\n",
    "            'Oz',\n",
    "            'PO4',\n",
    "            'P8',\n",
    "            'P6',\n",
    "            'P4',\n",
    "            'P2',\n",
    "            'CP4',\n",
    "            'T8',\n",
    "            'C6',\n",
    "            'C4',\n",
    "            'C2',\n",
    "            'FC4',\n",
    "            'F4',\n",
    "            'F8'\n",
    "              )\n",
    "\n",
    "channels = [i for i in range(3,17)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a pipeline is to create a session, which serves as a sandbox for all components in the pipeline. After creating the session we will create a graph which represents the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session and graph\n",
    "session = mp.Session.create()\n",
    "graph = mp.Graph.create(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create an LSL input stream using the ```create_marker_coupled_data_stream()``` factory method. We will pass in the session, the stream predicate, the channels, the time offset, and the marker format to create the LSL object.\n",
    "\n",
    "Then, we will create a tensor from the LSL input stream to serve as one input to our addition node. The LSL stream is volatile so to create the tensor, we will use the ```create_from_handle()``` factory method and pass in our LSL input stream object that we just created. \n",
    "\n",
    "We will create a second input tensor using the ```create_from_data()``` factory method.\n",
    "\n",
    "We will also create a tensor to store our output data. For the output tensor, the library will automatically determine the correct size for the tensor, so we can create a \"virtual\" tensor, meaning that it can be modified by the library and does not contain any user provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSLInputStream using the factory method\n",
    "# To create the object, we must pass the session, the stream predicate, the channels, the time offset, and the marker format\n",
    "# Alternatively, we can pass the data and marker stream infos, which are pylsl.StreamInfo objects\n",
    "\n",
    "lsl_object = mp.source.InputLSLStream.create_marker_coupled_data_stream(\n",
    "    session, \"type='EEG'\",\n",
    "    channels, 0, marker_fmt=\"^SPACE pressed$\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a tensor from the LSLInputStream. Since the LSL stream is volatile (not static) between trials,\n",
    "# we create the tensor from \"handle\", passing the stream object and the shape of the tensor\n",
    "t_in = mp.Tensor.create_from_handle(session, (len(channels), 1), lsl_object)\n",
    "\n",
    "# Create a second tensor from data, passing the session, the shape, and the data\n",
    "t_in_2 = mp.Tensor.create_from_data(session, data=np.zeros(t_in.shape))\n",
    "\n",
    "# Create an output tensor\n",
    "t_out = mp.Tensor.create_virtual(session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add our addition node to the graph using the ```add_to_graph()``` factory method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an addition node to the graph, passing the graph, the input tensors, and the output tensor\n",
    "Add = mp.kernels.AdditionKernel.add_to_graph(graph, t_in, t_in_2, t_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have created the processing pipeline, and added all of the required components. We can now use a graph method to verify that the structure of the pipeline is valid.\n",
    "\n",
    "Following the verification of the pipeline, we should now initialize the graph. This step is required for pipelines that have methods that need to be trained or fit (ie. classifiers), but optional for other pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify and initialize the graph\n",
    "graph.verify()\n",
    "graph.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will execute the graph 10 times, printing each sum output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # Execute the graph. The execute method will automatically wait for the correct marker\n",
    "    sts = graph.execute()\n",
    "    print(t_out.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcipy_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
