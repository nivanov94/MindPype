{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindpype as mp\n",
    "import pkgutil, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a pipeline is to create a session, which serves as a sandbox for all components in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline using the factory method\n",
    "session = mp.Session.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the creation of the pipeline, we need to create the graphs, which are the representations of the pipeline in MindPype.\n",
    "\n",
    "Each distinct pipeline would require a different graph object. For this tutorial, we will only require a single graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph using the factory method\n",
    "graph = mp.Graph.create(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a graph created, we can now attach our input and output data containers. Since the input data is known, we can create a tensor (the data container in MindPype), using the ```create_from_data()``` factory method. For the output tensor, the library will automatically determine the correct size for the tensor, so we can create a \"virtual\" tensor, meaning that it can be modified by the library and does not contain any user provided data.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random input tensor using the factory method\n",
    "input_tensor = mp.Tensor.create_from_data(session, shape=(10, 10), data=np.random.rand(10, 10))\n",
    "\n",
    "# Create an output tensor using the factory method\n",
    "output_tensor = mp.Tensor.create(session, shape=(10, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the input and output tensors, we can know add the processing nodes to the pipeline. For this example, we are using a single processing step, or kernel; the baseline correction kernel. We can use the following factory method to add  the kernel to a node, and add the node to the graph we created previously.\n",
    "\n",
    "Futhermore, we must pass the input and output tensors, as well as the required parameters for the kernel (in this case, the baseline period), to the factory method shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the baseline node, passing the graph, input tensor, output tensor, and baseline period\n",
    "baseline_node = mp.kernels.BaselineCorrectionKernel.add_baseline_node(graph, input_tensor, output_tensor, baseline_period = [0, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have created the processing pipeline, and added all of the required components. We can now use a graph method to verify that the structure of the pipeline is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the structure and inputs/outputs of the graph\n",
    "graph.verify()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the verification of the pipeline, we should now initialize the graph. This step is required for pipelines that have methods that need to be trained or fit (ie. classifiers), but optional for other pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the graph - optional for this pipeline\n",
    "graph.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is now ready to execute the provided input data. For other paradigms, we may opt to execute the graph in a loop. If we were using class-separated data, we would need to pass a task label to poll the correct task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the graph\n",
    "graph.execute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the input and output data\n",
    "print(input_tensor.data)\n",
    "print(output_tensor.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm proper functionality\n",
    "corrected = input_tensor.data - np.mean(input_tensor.data, axis = -1, keepdims = True)\n",
    "\n",
    "assert np.allclose(output_tensor.data, corrected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcipy_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
