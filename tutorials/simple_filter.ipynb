{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will demonstrate how to create a simple filter pipeline using MindPype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to setup the path so we can import the mindpype library\n",
    "import os; os.sys.path.append(os.path.dirname(os.path.abspath('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mindpype and numpy\n",
    "import mindpype as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to creating a pipeline is to create a session, which serves as a sandbox for all components in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a MindPype session object\n",
    "# a session is a container for all the mindpype data and graphs\n",
    "sess = mp.Session.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a graph to represent our pipeline.\n",
    "\n",
    "We will also define some session parameters that will be used to create our data source and filter node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the graph object and define some parameters\n",
    "online_graph = mp.Graph.create(sess)\n",
    "\n",
    "Fs = 128\n",
    "l_freq = 1\n",
    "h_freq = 40\n",
    "Nc = 14\n",
    "Ns = int(Fs * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a filter object that we will later pass into our filter node when we add it to our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the filter object\n",
    "f = mp.Filter.create_fir(sess, Fs, l_freq, h_freq, method='fir', phase='minimum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create an LSL input stream using the ```create_marker_uncoupled_data_stream()``` method. Since we do not need a marker stream for this filter tutorial, we will create a marker uncoupled data stream as opposed to a marker coupled data stream.\n",
    "\n",
    "Then, we will use our LSL object to create an Tensor to hold our online inputs by using the ```create_from_handle()``` factory method.\n",
    "\n",
    "Next, we will create virtual tensors to store all of our intermediate data calculated in our pipeline by using the ```create_virtual()``` factory method. Since these edges represent intermediate data that is only required in the process of completing a calculation and we don't need to access them at a later point we use the virtual type. \n",
    "\n",
    "We will also create a Tensor to store our output data. We can create a Tensor of a specified shape using the ```Tensor.create()``` factory method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the source object\n",
    "LSL_data_src = mp.source.InputLSLStream.create_marker_uncoupled_data_stream(sess, pred=\"type='EEG'\", channels=np.arange(3,17), interval=2.0, Ns=Ns)\n",
    "online_input_data = mp.Tensor.create_from_handle(sess, (Nc, Ns), LSL_data_src)\n",
    "\n",
    "# create the virtual tensor edges\n",
    "v_tensors = [\n",
    "    mp.Tensor.create_virtual(sess),  # 0 - output of pad, input to filter\n",
    "    mp.Tensor.create_virtual(sess),  # 1 - output of filter, input to extract\n",
    "]\n",
    "\n",
    "# define the output tensor\n",
    "online_output_data = mp.Tensor.create(sess, (Nc, Ns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add our nodes to the graph using the ```add_to_graph()``` method. For our filter kernel we will pad our input data, apply our filter to the padded data, and then extract the original indices from the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the nodes to the graph\n",
    "# pad the data\n",
    "mp.kernels.PadKernel.add_to_graph(\n",
    "    online_graph,\n",
    "    online_input_data,\n",
    "    v_tensors[0],\n",
    "    pad_width=((0, 0), (len(f.coeffs[\"fir\"]), len(f.coeffs[\"fir\"]))),\n",
    "    mode=\"edge\"\n",
    ")\n",
    "\n",
    "mp.kernels.FilterKernel.add_to_graph(\n",
    "    online_graph, v_tensors[0], f, v_tensors[1], axis=1,\n",
    ")\n",
    "\n",
    "start_time = 0.0\n",
    "end_time = 10.0\n",
    "start_ix = int(start_time * Fs) + len(f.coeffs[\"fir\"])\n",
    "end_ix = int(np.ceil(end_time * Fs)) + len(f.coeffs[\"fir\"])\n",
    "extract_indices = [\n",
    "    slice(None),\n",
    "    slice(start_ix, end_ix),\n",
    "]  # All epochs, all channels, start_time to end_time\n",
    "\n",
    "mp.kernels.ExtractKernel.add_to_graph(\n",
    "    online_graph, v_tensors[1], extract_indices, online_output_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then verify the graph using the ```verify()``` method. Verifying the graph orders the nodes for execution and ensure that the inputs and outputs of each processing node are appropriately typed and sized.\n",
    "\n",
    "After our graph has been verified, the next step is to initialize the graph. For our graph there is nothing to initialize so this step is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify and initialize the graph\n",
    "online_graph.verify()\n",
    "online_graph.initialize() # there is nothing to initialize in this graph, so this will do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will run our pipeline by calling the ```execute``` method on our graph. We will also plot our outputted, filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# change the plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (12 ,8)\n",
    "\n",
    "def plot_trial(X):\n",
    "    fig, ax = plt.subplots()\n",
    "    #ax.clear()\n",
    "    t = np.arange(0, X.shape[1]/128, 1/128)\n",
    "    for i_ch, ch in enumerate(range(X.shape[0])):\n",
    "        ax.plot(t, X[i_ch,:]+i_ch*200, label=ch)\n",
    "    ax.set_yticks(())\n",
    "    ax.set_xlabel('Time (s)', fontsize=28)\n",
    "    plt.show()\n",
    "\n",
    "# execute the graph\n",
    "while True:\n",
    "    tic = time.time()\n",
    "    online_graph.execute()\n",
    "    toc = time.time()\n",
    "    print(f\"Execution time: {toc-tic}\")\n",
    "    plot_trial(online_output_data.data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindpype",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
